{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "data = [\n",
    "    (\"This is a fantastic movie that I highly recommend.\", \"positive\"),\n",
    "    (\"I was pleasantly surprised by how much I enjoyed this movie.\", \"positive\"),\n",
    "    (\"This movie exceeded my expectations.\", \"positive\"),\n",
    "    (\"I can't stop raving about how great this movie is.\", \"positive\"),\n",
    "    (\"Definitely a must-watch for movie enthusiasts.\", \"positive\"),\n",
    "    (\"The acting and storyline were just brilliant.\", \"positive\"),\n",
    "    (\"I was on the edge of my seat the whole time. So intense!\", \"positive\"),\n",
    "    (\"The cinematography was outstanding; such a visually pleasing movie.\", \"positive\"),\n",
    "    (\"A 5 star movie until the final scene.\", \"positive\"),\n",
    "    (\"Awesome. This book is worth its weight in gold for the insights and understanding it shares...\", \"positive\"),\n",
    "    (\"This book does something I've never seen before...\", \"positive\"),\n",
    "    (\"If you don't own this dvd you need to add it to your collection. In my opinion it is the best american animated film ever released\", \"positive\"),\n",
    "    (\"Denzel Washington is great but Angelina Jolie he is even better. The movie itself is pretty scary...\", \"positive\"),\n",
    "    (\"I rediscovered this after a long time. This is a great series.I had never seen this in its entirety...\", \"positive\"),\n",
    "    (\"I bought this movie for my coming of age daughter to watch with me.  I enjoyed it so much in high school...\", \"positive\"),\n",
    "    (\"R.J. The Raccoon (Bruce Willis) was just looking for something to eat as he stumbles into his bear friend's cave...\", \"positive\"),\n",
    "    (\"9 to 5 was the first film to address the glass ceiling.  It takes a look at the workplace from a woman's view.\", \"positive\"),\n",
    "    (\"I wanted to do a grad school paper on something I was interested in researching and I picked Hip-Hop...\", \"positive\"),\n",
    "    (\"Although the scenes in this film were totally unrealistic, it was very interesting to see the point of view of people in the industry who have been blacklisted by the House Unamerican Activities Committee. In this day and age when actors still support politicians who support the Communist Party, it's interesting to see what went on 50 years ago.\", \"positive\"),\n",
    "    (\"A 5 star movie until the final scene.\", \"positive\"),\n",
    "    (\"Very, very funny! Good for all ages.\", \"positive\"),\n",
    "    (\"For the first time in a long time...a movie theater audience clapped and cheered at the end.\", \"positive\"),\n",
    "    (\"As a comic book fan, I found this film thoroughly entertaining. Good action, great animation, and a fair amount of humor.\", \"positive\"),\n",
    "    (\"I thought it was very funny and although a bit outlandish at times, that was the point! Very entertaining.\", \"positive\"),\n",
    "    (\"A good movie with a very good ending. The plot is great.\", \"positive\"),\n",
    "    (\"A very moving film. Not just a tear jerker.\", \"positive\"),\n",
    "    (\"This is a very interesting look at the music industry...\", \"positive\"),\n",
    "    (\"This is a fantastic movie that I highly recommend.\", \"positive\"),\n",
    "    (\"I was pleasantly surprised by how much I enjoyed this movie.\", \"positive\"),\n",
    "    (\"This movie exceeded my expectations.\", \"positive\"),\n",
    "    (\"I can't stop raving about how great this movie is.\", \"positive\"),\n",
    "    (\"Definitely a must-watch for movie enthusiasts.\", \"positive\"),\n",
    "    (\"I'm so glad I watched this movie; it's a true gem.\", \"positive\"),\n",
    "    (\"I can't find a single negative thing to say about this movie.\", \"positive\"),\n",
    "    (\"The best movie I've seen in a long time!\", \"positive\"),\n",
    "    (\"The acting and storyline were just brilliant.\", \"positive\"),\n",
    "    (\"I was on the edge of my seat the whole time. So intense!\", \"positive\"),\n",
    "    (\"The cinematography was outstanding; such a visually pleasing movie.\", \"positive\"),\n",
    "    (\"I was very disappointed with this movie.\", \"negative\"),\n",
    "    (\"I like to use the Amazon reviews...\", \"negative\"),\n",
    "    (\"This book was horrible...\", \"negative\"),\n",
    "    (\"I'm not sure who's writing these reviews...\", \"negative\"),\n",
    "    (\"I picked up the first book in this series...\", \"negative\"),\n",
    "    (\"Not only do I disagree with his opinions...\", \"negative\"),\n",
    "    (\"I have received your new book against the human race...\", \"negative\"),\n",
    "    (\"This book was on somebody's Amazon.com LISTMANIA for Sea Turtles...\", \"negative\"),\n",
    "    (\"This is one of those books that everyone raves about...\", \"negative\"),\n",
    "    (\"The concept of this book was interesting...\", \"negative\"),\n",
    "    (\"This entire movie could have run in only 20 minutes and you wouldn't miss anything and might even enjoy it. Unfortunately it ran 88 minutes too long and I couldn't wait for it to end. I saw it in the theater and the people all around me were all complaining how boring it was. At least a quarter of them walked out before the end. It's that bad. It's a shame, I love a good suspense/horror movie and the decent actors in this movies were waisted\", \"negative\"),\n",
    "    (\"If you are looking for a good movie to buy for your child, pass on this one. This movie has so many drug references, i can't even begin to explain.(trust me, I just so happen to have taken acid before) This is a movie that NEVER should have been directed toward children. If you want your child to be drug free when he/she grows up, do not buy this\", \"negative\"),\n",
    "    (\"Fun to watch but my 9 1/2 yr. old daughter could not follow the moves. Neither could I for that matter. We tried to learn the moves through \\\"breaking it down\\\" but there is just not enough repetition. Too complicated.\", \"negative\"),\n",
    "    (\"Every review I've read about this movie pops and fizzes with praise and I just don't get it. No one speaks until practically 10 minutes into it, and by then you're so confused by the random scenes thrown together and the cyrilic letters, it makes it hard to enjoy what comes next. If you like extremely BROAD slapstick humor and find that totally charming, then I guess I can see the appeal. I have to wonder what they could be: \\\"Damned Melon!\\\" or \\\"I passed out when I broke my wrist, and when I woke up, the cast was already on!\\\"??? I will say listening to the dubbed english and having the english subtitles on at the same time does add some humor, because they say completely different things, or omit speech altogether. In sum, don't waste your time\", \"negative\"),\n",
    "    (\"The acting was very good. The pace was adequate. However, the plot was predictable. The movie just reeks of the intelligent thriller syndrome. Clive's character kept calling this the perfect robbery. The characters talk about the relative intelligence of the other characters or how the other characters can't possibly know what is going on. I'm still not sure what Jody Foster's character brings to the plot. Any way, they do stupid things. The bank robbers dig a latrine in a storage closet. You don't know the hole is a latrine until the end of the movie. However, they do call it a \\\"s--thole during the movie. They spent hours on this hole. Why not use a bucket instead of a hole in the floor for a latrine? They even brought buckets in with them. They were disguised as painters. Why couldn't Clive's character use a bucket with chemical treatments instead of a hole in a floor of a bank for a latrine. Finding plot holes in this movie is like shooting fish in the barrel. Furthermore, the plot is so predictable that it made the movie drag. I have to be honest, I didn't guess the ending. I kicked myself for they gave plenty of clues. For example, a big one is the title of the movie. However, the lame clues (the s--thole) acted like red herrings. They threw me off the scent.\", \"negative\"),\n",
    "    (\"Wedding Crashers is the kinda film alot of people will love because it is stupid but alot of others like myself, won't enjoy. two womanizers fall in love, one because he finds out that his partner has a daughter, the other falls in love because it's the last girl left, I didn't like this film but i have to say, It is not a film for me, there are people who will absolutely love this film but i am not one of them\", \"negative\"),\n",
    "    (\"This movie is not worth watching.\", \"negative\"),\n",
    "    (\"Save yourself the trouble and skip this movie.\", \"negative\"),\n",
    "    (\"I was very disappointed with this movie.\", \"negative\"),\n",
    "    (\"I can never get the time I wasted on this movie back.\", \"negative\"),\n",
    "    (\"This is two hours of my life that I'll never get back.\", \"negative\"),\n",
    "    (\"I wish I could give this movie a zero.\", \"negative\"),\n",
    "    (\"I want my money back for the ticket I bought to see this movie.\", \"negative\"),\n",
    "    (\"I'm sorry, but this movie was terrible.\", \"negative\"),\n",
    "    (\"I wouldn't recommend this movie to anyone.\", \"negative\"),\n",
    "    (\"The worst movie I've ever seen. A complete waste of time.\", \"negative\"),\n",
    "    (\"I couldn't even finish watching this movie; that's how bad it was.\", \"negative\"),\n",
    "    (\"I regret every second I spent watching this awful movie.\", \"negative\"),\n",
    "    (\"I can't believe I had the misfortune of watching this movie.\", \"negative\"),\n",
    "    (\"I wish I could erase this movie from my memory.\", \"negative\"),\n",
    "    (\"The chemistry between the actors felt forced and unnatural.\", \"negative\"),\n",
    "    (\"I found the plot to be confusing and disjointed.\", \"negative\"),\n",
    "    (\"The dialogue was cringeworthy at best.\", \"negative\"),\n",
    "    (\"It's clear that no effort was put into making this movie.\", \"negative\"),\n",
    "    (\"The more I think about this movie, the worse it gets.\", \"negative\"),\n",
    "    (\"I honestly can't understand how anyone could enjoy this.\", \"negative\"),\n",
    "    (\"I kept waiting for something interesting to happen, but it never did.\", \"negative\"),\n",
    "    (\"The characters were unlikable and the storyline was boring.\", \"negative\"),\n",
    "]\n",
    "\n",
    "# Clean the data (punctuation, lowercase)\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split data into comments and labels\n",
    "comments = [item[0] for item in data]\n",
    "labels = [item[1] for item in data]\n",
    "\n",
    "cleaned_comments = [clean_text(comment) for comment in comments]\n",
    "\n",
    "# Tokenize and encode the words in the review\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(cleaned_comments)\n",
    "sequences = tokenizer.texts_to_sequences(cleaned_comments)\n",
    "padded_sequences = pad_sequences(\n",
    "    sequences, maxlen=300, padding='post', truncating='post')\n",
    "\n",
    "# Encode the labels for 'positive' and 'negative'\n",
    "label_mapping = {\"negative\": 0, \"positive\": 1}\n",
    "numeric_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# Conduct outlier removal to eliminate short sequences\n",
    "MIN_SEQUENCE_LENGTH = 50\n",
    "filtered_indices = [i for i, seq in enumerate(\n",
    "    padded_sequences) if len(seq) >= MIN_SEQUENCE_LENGTH]\n",
    "filtered_padded_sequences = padded_sequences[filtered_indices]\n",
    "filtered_numeric_labels = numeric_labels[filtered_indices]\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    filtered_padded_sequences, filtered_numeric_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "    train_features, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Enhanced model architecture with an LSTM layer\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=10000, output_dim=128, input_length=300),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_features, train_labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_features, val_labels))\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_features, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Updated prediction function\n",
    "\n",
    "def predict_sentiment(input_text):\n",
    "    cleaned_input = clean_text(input_text)\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_input])\n",
    "    padded_sequence = pad_sequences(\n",
    "        sequence, maxlen=300, padding='post', truncating='post')\n",
    "    sentiment_prob = model.predict(padded_sequence)[0][0]\n",
    "\n",
    "    if sentiment_prob > 0.5:\n",
    "        return \"Positive\", sentiment_prob\n",
    "    else:\n",
    "        return \"Negative\", 1 - sentiment_prob\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"Enter a review: \")\n",
    "    sentiment, confidence = predict_sentiment(user_input)\n",
    "\n",
    "    print(f\"Predicted sentiment: {sentiment}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split data into comments and labels\n",
    "comments = [item[0] for item in data]\n",
    "labels = [item[1] for item in data]\n",
    "\n",
    "cleaned_comments = [clean_text(comment) for comment in comments]\n",
    "\n",
    "# Tokenize and encode the words in the review\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(cleaned_comments)\n",
    "sequences = tokenizer.texts_to_sequences(cleaned_comments)\n",
    "padded_sequences = pad_sequences(\n",
    "    sequences, maxlen=300, padding='post', truncating='post')\n",
    "\n",
    "# Encode the labels for 'positive' and 'negative'\n",
    "label_mapping = {\"negative\": 0, \"positive\": 1}\n",
    "numeric_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# Conduct outlier removal to eliminate short sequences\n",
    "MIN_SEQUENCE_LENGTH = 50\n",
    "filtered_indices = [i for i, seq in enumerate(\n",
    "    padded_sequences) if len(seq) >= MIN_SEQUENCE_LENGTH]\n",
    "filtered_padded_sequences = padded_sequences[filtered_indices]\n",
    "filtered_numeric_labels = numeric_labels[filtered_indices]\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    filtered_padded_sequences, filtered_numeric_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "    train_features, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Enhanced model architecture with an LSTM layer\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=10000, output_dim=128, input_length=300),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_features, train_labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_features, val_labels))\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_features, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Updated prediction function\n",
    "\n",
    "def predict_sentiment(input_text):\n",
    "    cleaned_input = clean_text(input_text)\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_input])\n",
    "    padded_sequence = pad_sequences(\n",
    "        sequence, maxlen=300, padding='post', truncating='post')\n",
    "    sentiment_prob = model.predict(padded_sequence)[0][0]\n",
    "\n",
    "    if sentiment_prob > 0.5:\n",
    "        return \"Positive\", sentiment_prob\n",
    "    else:\n",
    "        return \"Negative\", 1 - sentiment_prob\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"Enter a review: \")\n",
    "    sentiment, confidence = predict_sentiment(user_input)\n",
    "\n",
    "    print(f\"Predicted sentiment: {sentiment}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
