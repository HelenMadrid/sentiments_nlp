{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "#import lxml.etree as ET\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "book_positive ='/Users/helenamadrid/Downloads/sorted_data_acl/books/books_positive_review.xml'\n",
    "book_negative = '/Users/helenamadrid/Downloads/sorted_data_acl/books/books_negative_review.xml'\n",
    "\n",
    "kitchen_housewares_negative = '/Users/helenamadrid/Downloads/sorted_data_acl/kitchen_&_housewares/kitchen_housewares_negative_review.xml'\n",
    "kitchen_housewares_positive = '/Users/helenamadrid/Downloads/sorted_data_acl/kitchen_&_housewares/kitchen_housewares_positive_review.xml'\n",
    "\n",
    "dvd_positive = '/Users/helenamadrid/Downloads/sorted_data_acl/dvd/dvd_positive_review.xml'\n",
    "dvd_negative = '/Users/helenamadrid/Downloads/sorted_data_acl/dvd/dvd_negative_review.xml'\n",
    "\n",
    "electronics_positive = '/Users/helenamadrid/Downloads/sorted_data_acl/electronics/electronics_positive_review.xml'\n",
    "electronics_negative = '/Users/helenamadrid/Downloads/sorted_data_acl/electronics/electronics_negative_review.xml'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electronics Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the XML content as a string\n",
    "with open(electronics_negative, 'r', encoding='utf-8') as xml_file:\n",
    "    xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_elec_N = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_elec_N.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_electronics_negative = pd.DataFrame(cleaned_data_elec_N, columns=columns)\n",
    "df_electronics_negative['Review'] = 'negative'\n",
    "\n",
    "#table = tabulate(df_electronics_negative.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_electronics_negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electronics Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the XML content as a string\n",
    "with open(electronics_positive, 'r', encoding='utf-8') as xml_file:\n",
    "    xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_elec_P = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_elec_P.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_electronics_positive = pd.DataFrame(cleaned_data_elec_P, columns=columns)\n",
    "df_electronics_positive['Review'] = 'positive'\n",
    "\n",
    "#table = tabulate(df_electronics_positive.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_electronics_positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read the XML content as a string\n",
    "with open(book_positive, 'r', encoding='utf-8') as xml_file:\n",
    "   xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('<;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('>;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_book_P = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_book_P.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_book_P = pd.DataFrame(cleaned_data_book_P, columns=columns)\n",
    "df_book_P['Review'] = 'positive'\n",
    "\n",
    "#table = tabulate(df_book_P.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_book_P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read the XML content as a string\n",
    "with open(book_negative, 'r', encoding='utf-8') as xml_file:\n",
    "   xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('<;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('>;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_book_N = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_book_N.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_book_N = pd.DataFrame(cleaned_data_book_N, columns=columns)\n",
    "df_book_N['Review'] = 'negative'\n",
    "\n",
    "#table = tabulate(df_book_N.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_book_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dvd Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read the XML content as a string\n",
    "with open(dvd_positive, 'r', encoding='utf-8') as xml_file:\n",
    "   xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('<;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('>;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_dvd_P = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_dvd_P.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_dvd_P= pd.DataFrame(cleaned_data_dvd_P, columns=columns)\n",
    "df_dvd_P['Review'] = 'positive'\n",
    "\n",
    "#table = tabulate(df_dvd_P.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_dvd_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DVD Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read the XML content as a string\n",
    "with open(dvd_negative, 'r', encoding='utf-8') as xml_file:\n",
    "   xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('<;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('>;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_dvd_N = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_dvd_N.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_dvd_N= pd.DataFrame(cleaned_data_dvd_N, columns=columns)\n",
    "df_dvd_N['Review'] = 'negative'\n",
    "\n",
    "#table = tabulate(df_dvd_N.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_dvd_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kitchen Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read the XML content as a string\n",
    "with open(kitchen_housewares_positive, 'r', encoding='utf-8') as xml_file:\n",
    "   xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('<;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('>;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_kitchen_P = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_kitchen_P.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_kitchen_P= pd.DataFrame(cleaned_data_kitchen_P, columns=columns)\n",
    "df_kitchen_P['Review'] = 'positive'\n",
    "\n",
    "#table = tabulate(df_kitchen_P.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_kitchen_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kitchen Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read the XML content as a string\n",
    "with open(kitchen_housewares_negative, 'r', encoding='utf-8') as xml_file:\n",
    "   xml_content = xml_file.read()\n",
    "\n",
    "# Remove the invalid character (ASCII value 26)\n",
    "cleaned_xml_content = xml_content.replace('\\x1A', '')\n",
    "\n",
    "# Replace any special symbols with their Unicode escape sequences\n",
    "cleaned_xml_content = cleaned_xml_content.replace('�', '')\n",
    "\n",
    "# Replace common entity references with their corresponding characters\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&lt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&gt;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&amp;', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&quot;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#62;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#60;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&#45;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('<;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('>;', '')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('&', 'and')\n",
    "cleaned_xml_content = cleaned_xml_content.replace('%*&#@', '')\n",
    "cleaned_xml_content = cleaned_xml_content.lower()\n",
    "cleaned_xml_content = re.sub(r\"[^a-zA-Z0-9\\s!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", cleaned_xml_content)\n",
    "\n",
    "\n",
    "# Parse the cleaned XML content using ElementTree\n",
    "root = ET.fromstring(cleaned_xml_content)\n",
    "\n",
    "# Clean the XML data by removing special characters and non-ASCII characters\n",
    "cleaned_data_kitchen_N = []\n",
    "\n",
    "for custom_tag in root.findall('review'):\n",
    "    values = []\n",
    "    for field in custom_tag:\n",
    "        cleaned_text = field.text.strip()\n",
    "        values.append(cleaned_text)\n",
    "    cleaned_data_kitchen_N.append(values)\n",
    "\n",
    "# Define column names based on the fields you extracted\n",
    "columns = ['unique_id', 'asin', 'product_name', 'product_type','helpful','rating', 'title', 'date', 'reviewer', 'reviewer_location', 'review_text']  # Adjust column names accordingly\n",
    "\n",
    "# Create a DataFrame from the cleaned data\n",
    "df_kitchen_N= pd.DataFrame(cleaned_data_kitchen_N, columns=columns)\n",
    "df_kitchen_N['Review'] = 'negative'\n",
    "\n",
    "#table = tabulate(df_kitchen_N.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "#print(df_kitchen_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging:\n",
      "                                           review_text    Review\n",
      "0    he just looks away from where the spray emits-...  negative\n",
      "1    having read the other reviews of this product ...  negative\n",
      "2    sometimes it sprays when she barks, most of th...  negative\n",
      "3    this item is cheaply made and i sent it back. ...  negative\n",
      "4    initially, my dogs found the sound interesting...  negative\n",
      "..                                                 ...       ...\n",
      "995  i have the canon mp500 printer and canon rebel...  positive\n",
      "996  i tested my new canon i960 with a variety of p...  positive\n",
      "997  i've had this for at least 8 months now. we've...  positive\n",
      "998  this reciever is great!  it even gets receptio...  positive\n",
      "999  the gps works in both my dell axim x5 and in m...  positive\n",
      "\n",
      "[8000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('After merging:')\n",
    "#pd.concat([df_kitchen_N, df_kitchen_P], axis=0)\n",
    "all_kitchen_reviews = pd.concat([df_kitchen_N, df_kitchen_P], axis=0)\n",
    "all_dvd_reviews = pd.concat([df_dvd_N, df_dvd_P], axis=0)\n",
    "all_books_reviews = pd.concat([df_book_N, df_book_P], axis=0)\n",
    "all_electronics_reviews = pd.concat([df_electronics_negative, df_electronics_positive], axis=0)\n",
    "\n",
    "all_dataFrames = pd.concat([all_kitchen_reviews, all_dvd_reviews, all_books_reviews, all_electronics_reviews], axis=0)\n",
    "#table = tabulate(hola.tail(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "new_dataFrame = all_dataFrames[['review_text', 'Review']]\n",
    "\n",
    "#print(new_dataFrame)\n",
    "\n",
    "\n",
    "#Now you have your cleaned data in a DataFrame\n",
    "print(new_dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           review_text    Review\n",
      "215  this picture had some good potential but the d...  negative\n",
      "582  i'm very surprised that this product has as hi...  negative\n",
      "662  this thing is a workhorse... i use it every da...  positive\n",
      "27   of course i enjoy this movie, i ordered it aft...  positive\n",
      "343  my first grisham novel, and it reminded me of ...  negative\n",
      "..                                                 ...       ...\n",
      "226  my sons, 4 and 8, saw this book at a well know...  positive\n",
      "390  this novel was amazing.  it is just as good as...  positive\n",
      "860  i spent several hours searching and researchin...  negative\n",
      "603  this is my first time ever buying a really exp...  positive\n",
      "270  this is a product too unique for me not too tr...  positive\n",
      "\n",
      "[8000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "randomized_df = new_dataFrame.sample(frac=1, random_state=42)  # Set a random_state for reproducibility\n",
    "#print(randomized_df)\n",
    "#print(type(randomized_df))\n",
    "#table = tabulate(randomized_df.head(10), headers='keys', tablefmt='pretty')\n",
    "#print(table)\n",
    "\n",
    "# Now you have your cleaned data in a DataFrame\n",
    "print(randomized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate into reviews and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into comments and labels\n",
    "reviews = randomized_df['review_text']\n",
    "labels = randomized_df['Review']\n",
    "#print(reviews)\n",
    "#print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the words in the review\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "padded_sequences = pad_sequences(\n",
    "    sequences, maxlen=300, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the labels for 'positive' and 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels for 'positive' and 'negative'\n",
    "label_mapping = {\"negative\": 0, \"positive\": 1}\n",
    "numeric_labels = np.array([label_mapping[label] for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct outlier removal to eliminate short sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct outlier removal to eliminate short sequences\n",
    "MIN_SEQUENCE_LENGTH = 50\n",
    "filtered_indices = [i for i, seq in enumerate(\n",
    "    padded_sequences) if len(seq) >= MIN_SEQUENCE_LENGTH]\n",
    "filtered_padded_sequences = padded_sequences[filtered_indices]\n",
    "filtered_numeric_labels = numeric_labels[filtered_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    filtered_padded_sequences, filtered_numeric_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "    train_features, train_labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanced model architecture with an LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced model architecture with an LSTM layer\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=10000, output_dim=128, input_length=300),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "160/160 [==============================] - 16s 94ms/step - loss: 0.6733 - accuracy: 0.5895 - val_loss: 0.6373 - val_accuracy: 0.6352\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 15s 93ms/step - loss: 0.5418 - accuracy: 0.7373 - val_loss: 0.4566 - val_accuracy: 0.7742\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 16s 99ms/step - loss: 0.2891 - accuracy: 0.8850 - val_loss: 0.4569 - val_accuracy: 0.7828\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 17s 104ms/step - loss: 0.1273 - accuracy: 0.9596 - val_loss: 0.5865 - val_accuracy: 0.7805\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 16s 98ms/step - loss: 0.0578 - accuracy: 0.9850 - val_loss: 0.7687 - val_accuracy: 0.7742\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 16s 98ms/step - loss: 0.0319 - accuracy: 0.9908 - val_loss: 0.8379 - val_accuracy: 0.7758\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 16s 100ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.8903 - val_accuracy: 0.7547\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 16s 101ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 1.2049 - val_accuracy: 0.7539\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 16s 102ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 1.3335 - val_accuracy: 0.7461\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 16s 98ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 1.3396 - val_accuracy: 0.7539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17780e890>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_features, train_labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 25ms/step - loss: 1.2458 - accuracy: 0.7719\n",
      "Test Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_features, test_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted sentiment: Positive\n",
      "Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Updated prediction function\n",
    "\n",
    "def predict_sentiment(input_text):\n",
    "    cleaned_input = clean_text(input_text)\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_input])\n",
    "    padded_sequence = pad_sequences(\n",
    "        sequence, maxlen=300, padding='post', truncating='post')\n",
    "    sentiment_prob = model.predict(padded_sequence)[0][0]\n",
    "\n",
    "    if sentiment_prob > 0.5:\n",
    "        return \"Positive\", sentiment_prob\n",
    "    else:\n",
    "        return \"Negative\", 1 - sentiment_prob\n",
    "\n",
    "# ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = input(\"Enter a review: \")\n",
    "    sentiment, confidence = predict_sentiment(user_input)\n",
    "\n",
    "    print(f\"Predicted sentiment: {sentiment}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
